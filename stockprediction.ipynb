{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import In\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "import torch\n",
    "import yfinance\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NopTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "class DatetimeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def fromDate(self, date):\n",
    "        return (pd.to_datetime(date) - pd.to_datetime('1950-01-01')).days\n",
    "\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "            X = X.to_numpy()\n",
    "        if len(X.shape) != 2:\n",
    "            X = X.reshape(X.shape[0], 1)\n",
    "        return np.array([[self.fromDate(j) for j in i] for i in X])\n",
    "\n",
    "def writeToCSV(data, filename):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        for i in range(len(data[0]-1)):\n",
    "            outfile.write('0,')\n",
    "        outfile.write('0\\n')\n",
    "        for slice_2d in data:\n",
    "            for x in slice_2d[:-1]:\n",
    "                outfile.write(str(x) + ',')\n",
    "            outfile.write(str(slice_2d[-1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadRawFromCSV = os.path.exists('rawData.pkl')\n",
    "\n",
    "rawData = []\n",
    "\n",
    "if loadRawFromCSV:\n",
    "    with open('rawData.pkl', 'rb') as file:\n",
    "        rawData = pickle.load(file)\n",
    "else:\n",
    "    kStocks = 50\n",
    "\n",
    "    stocks = []\n",
    "\n",
    "    with ZipFile('stocks.zip') as zip:\n",
    "        for stock in zip.namelist():\n",
    "            if stock.startswith('stocks/'):\n",
    "                stocks.append(stock.split('/')[1].split('.')[0])\n",
    "\n",
    "    stocks = resample(stocks, n_samples=kStocks, random_state=0)\n",
    "\n",
    "    with ZipFile('stocks.zip') as zip:\n",
    "        for stock in stocks:\n",
    "            zip.extract(f'stocks/{stock}.csv')\n",
    "\n",
    "    namedStocks = [(stock, pd.read_csv('stocks/' + stock + '.csv')) for stock in stocks]\n",
    "\n",
    "    rawData = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for stock, stockData in namedStocks:\n",
    "        i += 1\n",
    "        print(f'Loading stock industry {i} of {kStocks}')\n",
    "        try:\n",
    "            sector = yfinance.Ticker(stock).info['sector']\n",
    "            sectorFeature = np.empty((len(stockData), 1), dtype=object)\n",
    "            sectorFeature.fill(sector)\n",
    "            rawData.append(np.c_[stockData, sectorFeature])\n",
    "        except:\n",
    "            print(f\"{stock} doesn't have a sector!\")\n",
    "            continue\n",
    "\n",
    "    with open('rawData.pkl', 'wb') as file:\n",
    "        pickle.dump(rawData, file)\n",
    "\n",
    "# loadPreprocessedFromCSV = os.path.exists('preprocessedData.pkl')\n",
    "loadPreprocessedFromCSV = False\n",
    "\n",
    "\n",
    "preprocessedData = []\n",
    "\n",
    "if loadPreprocessedFromCSV:\n",
    "    with open('preprocessedData.pkl', 'rb') as file:\n",
    "        preprocessedData = pickle.load(file)\n",
    "else:\n",
    "    DateIdx, OpenIdx,HighIdx,LowIdx,CloseIdx,Adj_CloseIdx,VolumeIdx,IndustryIdx = (0, 1, 2, 3, 4, 5, 6, 7)\n",
    "\n",
    "    pipeline = ColumnTransformer([\n",
    "        ('date pipeline', DatetimeTransformer(), DateIdx),\n",
    "        ('numerical pipeline', Pipeline([\n",
    "            ('nop', NopTransformer())\n",
    "            # ('scale features', StandardScaler())\n",
    "        ]), [OpenIdx, HighIdx, LowIdx, CloseIdx, Adj_CloseIdx, VolumeIdx]),\n",
    "        ('industry pipeline', OneHotEncoder(), [IndustryIdx])\n",
    "    ])\n",
    "\n",
    "    # print(rawData)\n",
    "    combinedStocks = []\n",
    "    for rawStock in rawData:\n",
    "        combinedStocks.extend(rawStock[-500:])\n",
    "\n",
    "    preprocessedData = pipeline.fit_transform(combinedStocks)\n",
    "\n",
    "    with open('preprocessedData.pkl', 'wb') as file:\n",
    "        pickle.dump(preprocessedData, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217575"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18077"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedStocks = preprocessedData\n",
    "\n",
    "# for preprocessedData in preprocessedData:\n",
    "#     concatenatedStocks.extend(preprocessedData)\n",
    "\n",
    "    # concatonated stocks index -stopping point\n",
    "\n",
    "# concatenatedStocks = concatenatedStocks[-500:]\n",
    "concatenatedStocks = np.array(concatenatedStocks)\n",
    "target = np.array(concatenatedStocks)[:, CloseIdx]\n",
    "concatenatedStocks = concatenatedStocks[:-1]\n",
    "target = target[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "n = concatenatedStocks.shape[0]\n",
    "window_size = 50\n",
    "for i in range(n-window_size):\n",
    "    X.append(concatenatedStocks[i:i+window_size])\n",
    "    y.append(target[i:i+window_size])\n",
    "\n",
    "X = np.array(X).astype(np.float32)\n",
    "y = np.array(y).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18026, 50, 15)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)\n",
    "x_train, x_test,y_train,y_test = train_test_split(X,y,test_size= .2)\n",
    "\n",
    "# x_train = np.array(x_train).astype(np.float32)\n",
    "# x_test = np.array(x_test).astype(np.float32)\n",
    "# y_train = np.array(y_train).astype(np.float32)\n",
    "# y_test = np.array(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.reshape(x_train.shape[0],7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(8, input_shape=(x_train.shape[1],x_train.shape[2]), return_sequences=False))\n",
    "model.add(Dense(2,kernel_initializer='normal',activation='linear'))\n",
    "model.add(Dense(1,kernel_initializer='normal',activation='linear'))\n",
    "model.compile(loss='mse',optimizer ='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=2000,batch_size=5,validation_split=0.05,verbose=0)\n",
    "\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    torch.save(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "with open('x_test.pkl', 'wb') as file:\n",
    "    pickle.dump(x_test, file)\n",
    "\n",
    "with open('y_pred.pkl', 'wb') as file:\n",
    "    pickle.dump(y_pred, file)\n",
    "\n",
    "def print_metrics(y_test, y_pred):\n",
    "    mse_test = mean_squared_error(y_test, y_pred) \n",
    "\n",
    "    rmse = np.sqrt(mse_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"%-12s %f\" % ('MSE:', mse_test))\n",
    "    print(\"%-12s %f\" % ('RMSE:', rmse))\n",
    "    print(\"%-12s %f\" % ('R2:', r2))\n",
    "    print(f'MAPE: {mean_absolute_percentage_error(y_test, y_pred)}')\n",
    "\n",
    "    def plotGraph(y_test,y_pred):\n",
    "        if max(y_test) >= max(y_pred):\n",
    "            my_range = int(max(y_test))\n",
    "        else:\n",
    "            my_range = int(max(y_pred))\n",
    "        plt.scatter(y_test, y_pred, color='red')\n",
    "        plt.plot(range(my_range), range(my_range), 'o')\n",
    "        plt.title('Testing vs Predicted')\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    plotGraph(y_test, y_pred)\n",
    "\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(name, model):\n",
    "    model.fit(x_test, y_test)\n",
    "    print(f'\\nModel: {name}')\n",
    "    print_metrics(y_test, model.predict(x_test))\n",
    "\n",
    "test_model('Linear Regression', LinearRegression())\n",
    "test_model('Random Forest', RandomForestRegressor())\n",
    "test_model('K-Nearest Neighbors', KNeighborsRegressor())\n",
    "test_model('Support Vector Machine (rbf)', SVR(kernel='rbf'))\n",
    "# # test_model('Support Vector Machine (linear)', SVR(kernel='linear'))\n",
    "# # test_model('Support Vector Machine (poly)', SVR(kernel='poly'))\n",
    "# # test_model('Support Vector Machine (sigmoid)', SVR(kernel='sigmoid'))\n",
    "test_model('Decision Tree', DecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.test.is_gpu_available()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71963e98eadabb68e8978a13f70499e318779c31367c0bef81974228087b6def"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
